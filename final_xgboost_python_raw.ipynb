{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-17T19:41:04.538139Z",
     "start_time": "2019-02-17T19:41:03.865340Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import KFold\n",
    "import warnings\n",
    "import time\n",
    "import sys\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "from scipy.stats import mode\n",
    "from scipy import stats\n",
    "import feather\n",
    "import re\n",
    "import warnings\n",
    "import random\n",
    "\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-17T19:41:05.002977Z",
     "start_time": "2019-02-17T19:41:04.540124Z"
    },
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "target = pd.read_csv('target2',header=None,index_col=0)\n",
    "train = feather.read_dataframe('best_from_recent_groupped_train')\n",
    "test = feather.read_dataframe('best_from_recent_groupped_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-17T19:41:05.241916Z",
     "start_time": "2019-02-17T19:41:05.003976Z"
    },
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "test_cardid = test['card_id']\n",
    "train = train[[c for c in train if c not in ['card_id', 'first_active_month','last_active_month']]]\n",
    "test = test[[c for c in train if c not in ['card_id', 'first_active_month','last_active_month']]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-17T19:41:05.247914Z",
     "start_time": "2019-02-17T19:41:05.243899Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "categorical_feats = [x for x in train if re.search('[th]_cat1_[^s]',x)]\n",
    "categorical_feats += [x for x in train if (re.search('modeplus',x) or re.search('feature_',x))]\n",
    "categorical_feats = list(set(categorical_feats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-17T19:41:07.524169Z",
     "start_time": "2019-02-17T19:41:05.248897Z"
    }
   },
   "outputs": [],
   "source": [
    "cut = train.shape[0]\n",
    "train = pd.concat([train,test])\n",
    "train = pd.get_dummies(train,columns=categorical_feats)\n",
    "test = train.iloc[cut:,:]\n",
    "train = train.iloc[:cut,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-17T19:41:05.493Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°0\n",
      "[0]\ttrain-rmse:3.93478\teval-rmse:3.98017\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 200 rounds.\n",
      "[500]\ttrain-rmse:3.56442\teval-rmse:3.67481\n",
      "[1000]\ttrain-rmse:3.48372\teval-rmse:3.67158\n",
      "Stopping. Best iteration:\n",
      "[1101]\ttrain-rmse:3.46794\teval-rmse:3.67055\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_test = 10\n",
    "best_x_test = np.nan\n",
    "for x_test in range(1):\n",
    "    params = {'max_depth': 4, \n",
    "              'eta': 0.02, \n",
    "              'objective': 'reg:linear',\n",
    "              'eval_metric': 'rmse',\n",
    "              'nthreads':2,\n",
    "              'subsample':0.9,\n",
    "              'alpha':0.4,\n",
    "              'tree_method':'gpu_hist',\n",
    "              'grow_policy':'lossguide',\n",
    "   #           'grow_policy':'depthwise',\n",
    "              'max_leaves':50,\n",
    "              'max_bin':87,\n",
    "              'seed':77,\n",
    "              'colsample_bytree':0.9,\n",
    "              'min_child_weight':19,\n",
    "              'max_delta_step':13,\n",
    "              \n",
    "              \n",
    "\n",
    "             }\n",
    "\n",
    "    folds = KFold(n_splits=5, shuffle=True, random_state=15)\n",
    "    oof = np.zeros(len(train))\n",
    "    predictions = np.zeros(len(test))\n",
    "    feature_importance_df = pd.DataFrame()\n",
    "\n",
    "    for fold_, (trn_idx, val_idx) in enumerate(folds.split(train.values, target.values)):\n",
    "        print(\"fold n°{}\".format(fold_))\n",
    "\n",
    "        dtrain = xgb.DMatrix(train.iloc[trn_idx],label=target.iloc[trn_idx])\n",
    "        dval = xgb.DMatrix(train.iloc[val_idx],label=target.iloc[val_idx])\n",
    "        dtest = xgb.DMatrix(test)\n",
    "\n",
    "\n",
    "        clf = xgb.train(params=params,\n",
    "              dtrain=dtrain,\n",
    "              evals=[(dtrain, 'train'),(dval, 'eval')],\n",
    "              num_boost_round=30000,\n",
    "              early_stopping_rounds=200,\n",
    "              verbose_eval=500)\n",
    "\n",
    "\n",
    "        oof[val_idx] = clf.predict(dval)\n",
    "\n",
    "        fold_importance_df = pd.DataFrame()\n",
    "        fold_importance_df[\"feature\"] = clf.get_fscore().keys()\n",
    "        fold_importance_df[\"importance\"] = clf.get_fscore().values()\n",
    "        fold_importance_df[\"fold\"] = fold_ + 1\n",
    "        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "\n",
    "        predictions += clf.predict(dtest) / folds.n_splits\n",
    "\n",
    "    errr = mean_squared_error(oof, target)**0.5\n",
    "    if errr < best_test:\n",
    "        best_test = errr\n",
    "        best_x_test = x_test\n",
    "    \n",
    "    print(\"CV score: {:<8.5f}\\n\".format(errr))\n",
    "    print(x_test, '- x_test \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-17T18:24:21.921Z"
    }
   },
   "outputs": [],
   "source": [
    "sub_df = pd.DataFrame({\"card_id\":test_cardid.values})\n",
    "sub_df[\"target\"] = predictions\n",
    "sub_df.to_csv(\"submit_with_all_additionsXGBOOST.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-17T18:24:21.923Z"
    }
   },
   "outputs": [],
   "source": [
    "best_test,best_x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-17T18:24:21.925Z"
    }
   },
   "outputs": [],
   "source": [
    "best_test,best_x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-17T18:24:21.928Z"
    }
   },
   "outputs": [],
   "source": [
    "cols = (feature_importance_df[[\"feature\", \"importance\"]]\n",
    "        .groupby(\"feature\")\n",
    "        .mean()\n",
    "        .sort_values(by=\"importance\", ascending=False)[:1000].index)\n",
    "\n",
    "best_features = feature_importance_df.loc[feature_importance_df.feature.isin(cols)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-17T18:24:21.929Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_cols = pd.DataFrame(best_features.groupby(['feature'])['importance'].mean()).sort_values(by='importance')\n",
    "all_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
